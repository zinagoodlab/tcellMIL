{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os \n",
    "from src.Dataset import load_and_explore_data, preprocess_data\n",
    "from src.Autoencoder import train_autoencoder, evaluate_autoencoder\n",
    "from src.MIL import AttentionMIL\n",
    "from src.train import leave_one_out_cross_validation\n",
    "\n",
    "\n",
    "def run_pipeline_loocv(input_file, output_dir='results',\n",
    "                       latent_dim=64, num_epochs_ae=200,\n",
    "                       num_epochs=50, num_classes=2,\n",
    "                       hidden_dim=128, sample_source_dim=4,\n",
    "                       project_name=\"tcellMIL\"):\n",
    "    \"\"\"run complete pipeline with leave one out cross validation\n",
    "    \n",
    "    Parameters:\n",
    "    - input_file: path to input file\n",
    "    - output_dir: directory to save results\n",
    "    - latent_dim: dimension of latent space\n",
    "    - num_epochs_ae: number of epochs for autoencoder\n",
    "    - num_epoch_mil: number of epochs for MIL\n",
    "    - num_classes: number of classes\n",
    "    - hidden_dim: dimension of hidden layer\n",
    "\n",
    "    Returns:\n",
    "    - dict of results and models\n",
    "    \"\"\"\n",
    "\n",
    "    # config = {\n",
    "    #     \"input_file\": input_file,\n",
    "    #     \"output_dir\": output_dir,\n",
    "    #     \"latent_dim\": latent_dim,\n",
    "    #     \"num_epochs_ae\": num_epochs_ae,\n",
    "    #     \"num_epochs_mil\": num_epochs,\n",
    "    #     \"num_classes\": num_classes,\n",
    "    #     \"hidden_dim\": hidden_dim,\n",
    "    #     \"cv_method\": \"leave-one-out\"\n",
    "    # }\n",
    "\n",
    "    # wandb.init(project=project_name, config=config)\n",
    "\n",
    "    # Create output directories\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    result_dir = os.path.join(output_dir, f\"run_{timestamp}\")\n",
    "    ae_dir = os.path.join(result_dir, \"autoencoder\")\n",
    "    mil_dir = os.path.join(result_dir, \"mil\")\n",
    "    \n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "    os.makedirs(ae_dir, exist_ok=True)\n",
    "    os.makedirs(mil_dir, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    # Step 1: Load and explore data\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 1: LOADING AND EXPLORING DATA\")\n",
    "    print(\"=\"*80)\n",
    "    adata = load_and_explore_data(input_file)\n",
    "\n",
    "    # wandb.config.update({\n",
    "    #     \"cells\": adata.n_obs,\n",
    "    #     \"TFs\": adata.n_vars,\n",
    "    #     \"patients\": adata.obs[\"patient_id\"].nunique()\n",
    "    # })\n",
    "\n",
    "    # if \"Response_3m\" in adata.obs.columns:\n",
    "    #     wandb.config.update({\n",
    "    #         \"Response_distribution\": dict(adata.obs[\"Response_3m\"].value_counts())\n",
    "    #     })\n",
    "\n",
    "    # step 2: train autoencoder\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 2: TRAINING AUTOENCODER\")\n",
    "    print(\"=\"*80)\n",
    "    train_loader, val_loader, test_loader, input_dim = preprocess_data(adata)\n",
    "\n",
    "    # Step 3:train autoencoder\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 3: TRAINING AUTOENCODER\")\n",
    "    print(\"=\"*80)\n",
    "    model, train_losses, val_losses = train_autoencoder(\n",
    "            train_loader, val_loader, input_dim, latent_dim, num_epochs_ae, save_path=ae_dir\n",
    "        )\n",
    "    adata_latent, test_loss = evaluate_autoencoder(\n",
    "        model, test_loader, adata, adata.var_names.tolist(), save_path=ae_dir\n",
    "    )\n",
    "    \n",
    "    # Save latent representations\n",
    "    latent_file = os.path.join(ae_dir, \"latent_representation.h5ad\")\n",
    "    adata_latent.write(latent_file)\n",
    "\n",
    "    # Step 4: Run LOOCV\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 4: RUNNING LEAVE-ONE-OUT CROSS-VALIDATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Check if we have response information\n",
    "    if 'Response_3m' not in adata_latent.obs.columns:\n",
    "        print(\"ERROR: 'response' column not found in the data. Cannot proceed with MIL.\")\n",
    "        # wandb.finish()\n",
    "        return None\n",
    "    \n",
    "    # Remove patients with NaN responses\n",
    "    patients_with_missing = adata_latent.obs[adata_latent.obs['Response_3m'].isna()]['patient_id'].unique()\n",
    "    if len(patients_with_missing) > 0:\n",
    "        print(f\"Removing {len(patients_with_missing)} patients with missing responses\")\n",
    "        adata_latent = adata_latent[~adata_latent.obs['patient_id'].isin(patients_with_missing)].copy()\n",
    "        \n",
    "\n",
    "    cv_results = leave_one_out_cross_validation(\n",
    "        adata_latent, \n",
    "        input_dim = latent_dim,\n",
    "        num_classes = num_classes, \n",
    "        hidden_dim = hidden_dim,\n",
    "        sample_source_dim = sample_source_dim,\n",
    "        num_epochs = num_epochs,\n",
    "        save_path = mil_dir\n",
    "    )\n",
    "        \n",
    "\n",
    "\n",
    "    # wandb.finish()\n",
    "\n",
    "    print(f\"Pipeline completed successfully! Results saved to {result_dir}\")\n",
    "\n",
    "    return {\n",
    "        'adata': adata,\n",
    "        'autoencoder': model,\n",
    "        'latent_data': adata_latent,\n",
    "        'mil_results': cv_results,\n",
    "        'results_dir': result_dir\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scVI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
